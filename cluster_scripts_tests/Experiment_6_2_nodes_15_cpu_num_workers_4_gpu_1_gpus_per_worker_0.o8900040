Allocate Nodes = <hpc-g01-node01 hpc-g02-node04>
set up ray cluster...


Working with node hpc-g01-node01
first allocate node - use as headnode ...
2022-10-05 12:01:30,272	INFO scripts.py:357 -- Using IP address 192.168.115.75 for this node.
2022-10-05 12:01:30,276	INFO resource_spec.py:212 -- Starting Ray with 165.33 GiB memory available for workers and up to 74.86 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 12:01:36,177	INFO services.py:1170 -- View the Ray dashboard at [1m[32mlocalhost:8265[39m[22m
2022-10-05 12:01:36,499	INFO scripts.py:387 -- 
Started Ray on this node. You can add additional nodes to the cluster by calling

    ray start --address='192.168.115.75:3679' --redis-password='09083cb7-7d66-4c03-900b-3c7558ca79da'

from the node you wish to add. You can connect a driver to the cluster from Python by running

    import ray
    ray.init(address='auto', redis_password='09083cb7-7d66-4c03-900b-3c7558ca79da')

If you have trouble connecting from a different machine, check that your firewall is configured properly. If you wish to terminate the processes that have been started, run

    ray stop

Working with node hpc-g02-node04
then allocate other nodes:  1
node NAME: hpc-g02-node04.unitn.it
node IP: 192.168.115.143
dest IP: 192.168.115.75:3679
2022-10-05 12:01:45,411	INFO scripts.py:429 -- Using IP address 192.168.115.143 for this node.
2022-10-05 12:01:45,417	INFO resource_spec.py:212 -- Starting Ray with 217.63 GiB memory available for workers and up to 93.28 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 12:01:45,455	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-g02-node04.unitn.it

done, now launching python program
Inside covid19_components.py: 1 GPUs are available.
Warning: The 'WarpDrive' package is not found and cannot be used! If you wish to use WarpDrive, please run 'pip install rl-warp-drive' first.
Inside covid19_env.py: 1 GPUs are available.
Warning: The 'WarpDrive' package is not found and cannot be used! If you wish to use WarpDrive, please run 'pip install rl-warp-drive' first.
2022-10-05 12:07:01,482	WARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster's _internal_config.
2022-10-05 12:07:01,529 seed (final): 22341000
2022-10-05 12:07:01,600	INFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
2022-10-05 12:07:04,458	INFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
Traceback (most recent call last):
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1378, in _do_call
2022-10-05 12:07:47,387	WARNING worker.py:1090 -- The actor or task with ID ffffffffffffffff45b95b1c0100 is pending and cannot currently be scheduled. It requires {CPU: 1.000000} for execution and {CPU: 1.000000} for placement, but this node only has remaining {node:192.168.115.75: 1.000000}, {CPU: 20.000000}, {memory: 165.332031 GiB}, {GPU: 1.000000}, {object_store_memory: 51.611328 GiB}. In total there are 0 pending tasks and 2 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
    return fn(*args)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1360, in _run_fn
    self._extend_graph()
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1401, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InternalError: Constraining by assigned device should not cause an error. Original root's assigned device name: /job:localhost/replica:0/task:0/device:GPU:0 node's assigned device name "/job:localhost/replica:0/task:0/device:CPU:0. Error: Cannot merge devices with incompatible types: '/job:localhost/replica:0/task:0/device:GPU:0' and '/job:localhost/replica:0/task:0/device:CPU:0'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ettore.saggiorato/ai-economist-ppo-decision-tree/ai-economist/tutorials/rllib/training_2_algos.py", line 408, in <module>
    trainerAgents, trainerPlanner = build_trainer(run_config)
  File "/home/ettore.saggiorato/ai-economist-ppo-decision-tree/ai-economist/tutorials/rllib/training_2_algos.py", line 196, in build_trainer
    * trainer_config.get("num_envs_per_worker"),
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 90, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 448, in __init__
    super().__init__(config, logger_creator)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/tune/trainable.py", line 174, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 591, in _setup
    self._init(self.config, self.env_creator)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 129, in _init
    self.optimizer = make_policy_optimizer(self.workers, config)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/agents/ppo/ppo.py", line 99, in choose_policy_optimizer
    _fake_gpus=config["_fake_gpus"])
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/optimizers/multi_gpu_optimizer.py", line 130, in __init__
    self.per_device_batch_size, policy.copy))
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/optimizers/multi_gpu_impl.py", line 92, in __init__
    len(input_placeholders)))
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/optimizers/multi_gpu_impl.py", line 292, in _setup_device
    graph_obj = self.build_graph(device_input_slices)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/policy/dynamic_tf_policy.py", line 300, in copy
    TFPolicy._initialize_loss(instance, loss, loss_inputs)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py", line 253, in _initialize_loss
    self._sess.run(tf.global_variables_initializer())
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 969, in run
    run_metadata_ptr)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1192, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1372, in _do_run
    run_metadata)
  File "/home/ettore.saggiorato/venv/ai-economist/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1397, in _do_call
    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter
tensorflow.python.framework.errors_impl.InternalError: Graph execution error:

Constraining by assigned device should not cause an error. Original root's assigned device name: /job:localhost/replica:0/task:0/device:GPU:0 node's assigned device name "/job:localhost/replica:0/task:0/device:CPU:0. Error: Cannot merge devices with incompatible types: '/job:localhost/replica:0/task:0/device:GPU:0' and '/job:localhost/replica:0/task:0/device:CPU:0'
