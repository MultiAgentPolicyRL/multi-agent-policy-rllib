Allocate Nodes = <hpc-g04-node02 hpc-g04-node01 hpc-g01-node02 hpc-g02-node02>
set up ray cluster...


Working with node hpc-g04-node02
first allocate node - use as headnode ...
2022-10-05 10:55:52,217	INFO scripts.py:357 -- Using IP address 192.168.115.44 for this node.
2022-10-05 10:55:52,220	INFO resource_spec.py:212 -- Starting Ray with 428.03 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:55:53,303	INFO services.py:1170 -- View the Ray dashboard at [1m[32mlocalhost:8265[39m[22m
2022-10-05 10:55:53,347	INFO scripts.py:387 -- 
Started Ray on this node. You can add additional nodes to the cluster by calling

    ray start --address='192.168.115.44:3679' --redis-password='bcdf75a2-dd1d-471f-b353-408eec032141'

from the node you wish to add. You can connect a driver to the cluster from Python by running

    import ray
    ray.init(address='auto', redis_password='bcdf75a2-dd1d-471f-b353-408eec032141')

If you have trouble connecting from a different machine, check that your firewall is configured properly. If you wish to terminate the processes that have been started, run

    ray stop

Working with node hpc-g04-node01
then allocate other nodes:  1
node NAME: hpc-g04-node01.unitn.it
node IP: 192.168.115.24
dest IP: 192.168.115.44:3679
2022-10-05 10:56:01,538	INFO scripts.py:429 -- Using IP address 192.168.115.24 for this node.
2022-10-05 10:56:01,541	INFO resource_spec.py:212 -- Starting Ray with 529.39 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:56:01,570	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-g04-node01.unitn.it

Working with node hpc-g01-node02
then allocate other nodes:  2
node NAME: hpc-g01-node02.unitn.it
node IP: 192.168.115.93
dest IP: 192.168.115.44:3679
2022-10-05 10:56:11,553	INFO scripts.py:429 -- Using IP address 192.168.115.93 for this node.
2022-10-05 10:56:11,556	INFO resource_spec.py:212 -- Starting Ray with 173.29 GiB memory available for workers and up to 74.28 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:56:11,556	WARNING services.py:1494 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 55419244544 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.
2022-10-05 10:56:11,574	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-g01-node02.unitn.it

Working with node hpc-g02-node02
then allocate other nodes:  3
node NAME: hpc-g02-node02.unitn.it
node IP: 192.168.115.10
dest IP: 192.168.115.44:3679
2022-10-05 10:56:21,624	INFO scripts.py:429 -- Using IP address 192.168.115.10 for this node.
2022-10-05 10:56:21,627	INFO resource_spec.py:212 -- Starting Ray with 218.46 GiB memory available for workers and up to 93.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:56:21,627	WARNING services.py:1494 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 68429537280 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.
2022-10-05 10:56:21,644	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-g02-node02.unitn.it

done, now launching python program
Inside covid19_components.py: 1 GPUs are available.
Warning: The 'WarpDrive' package is not found and cannot be used! If you wish to use WarpDrive, please run 'pip install rl-warp-drive' first.
Inside covid19_env.py: 1 GPUs are available.
Warning: The 'WarpDrive' package is not found and cannot be used! If you wish to use WarpDrive, please run 'pip install rl-warp-drive' first.
2022-10-05 10:57:42,002	WARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster's _internal_config.
2022-10-05 10:57:42,032 seed (final): 18182000
2022-10-05 10:57:42,095	INFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
2022-10-05 10:57:42,329	INFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
2022-10-05 10:58:03,485	INFO trainable.py:180 -- _setup took 21.157 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2022-10-05 10:58:03,485	INFO trainable.py:217 -- Getting current IP.
2022-10-05 10:58:17,602	INFO trainable.py:180 -- _setup took 14.033 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2022-10-05 10:58:17,602	INFO trainable.py:217 -- Getting current IP.
2022-10-05 10:58:17,631 Not restoring trainer...
2022-10-05 10:58:17,632 Starting with fresh agent TF weights.
2022-10-05 10:58:17,632 Starting with fresh planner TF weights.
Training
-- PPO Agents -- Steps done: 0
2022-10-05 11:01:45,586 Iter 1: steps this-iter 4000 total 4000 -> 4/5000 episodes done
2022-10-05 11:01:45,591 custom_metrics: {}
date: 2022-10-05_11-01-45
done: false
episode_len_mean: 1000.0
episode_reward_max: 409.9543729574029
episode_reward_mean: 346.42196277383147
episode_reward_min: 199.17922931462073
episodes_this_iter: 4
episodes_total: 4
experiment_id: e091da29812b42cd9a2c2920e11e4fe1
hostname: hpc-g04-node02.unitn.it
info:
  grad_time_ms: 143514.017
  learner:
    agent_policy:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 2.063002586364746
      entropy_coeff: 0.02500000037252903
      kl: 0.11596402525901794
      model: {}
      policy_loss: -0.17904573678970337
      total_loss: -0.17038996517658234
      vf_explained_var: 0.9017845392227173
      vf_loss: 1.2046165466308594
  load_time_ms: 1630.879
  num_steps_sampled: 4000
  num_steps_trained: 16000
  sample_time_ms: 54046.777
  update_time_ms: 7433.534
iterations_since_restore: 1
node_ip: 192.168.115.44
num_healthy_workers: 2
off_policy_estimator: {}
optimizer_steps_this_iter: 1
perf:
  cpu_util_percent: 59.472597864768694
  gpu_util_percent0: 0.0
  ram_util_percent: 22.352313167259787
  vram_util_percent0: 0.018997524752475247
pid: 23090
policy_reward_max:
  agent_policy: 105.24859206837552
  planner_policy: 150.8271455720931
policy_reward_mean:
  agent_policy: 57.49472460632731
  planner_policy: 116.44306434852093
policy_reward_min:
  agent_policy: 15.038367702716442
  planner_policy: 55.12339185110242
sampler_perf:
  mean_env_wait_ms: 2.277967871456728
  mean_inference_ms: 2.8579561547122556
  mean_processing_ms: 0.706245814604142
time_since_restore: 207.01415610313416
time_this_iter_s: 207.01415610313416
time_total_s: 207.01415610313416
timestamp: 1664960505
timesteps_since_restore: 4000
timesteps_this_iter: 4000
timesteps_total: 4000
training_iteration: 1

2022-10-05 11:01:45,790 >> Wrote dense logs to: /home/ettore.saggiorato/ai-economist-ppo-decision-tree/ai-economist/tutorials/rllib/experiments/check/phase1_gpu/dense_logs/logs_0000000000004000
-- PPO Agents -- Steps done: 4
2022-10-05 11:04:10,757 Iter 2: steps this-iter 4000 total 8000 -> 8/5000 episodes done
2022-10-05 11:04:10,763 custom_metrics: {}
date: 2022-10-05_11-04-10
done: false
episode_len_mean: 1000.0
episode_reward_max: 525.8075341328317
episode_reward_mean: 391.0534475381255
episode_reward_min: 199.17922931462073
episodes_this_iter: 4
episodes_total: 8
experiment_id: e091da29812b42cd9a2c2920e11e4fe1
hostname: hpc-g04-node02.unitn.it
info:
  grad_time_ms: 138330.809
  learner:
    agent_policy:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 2.0784692764282227
      entropy_coeff: 0.02500000037252903
      kl: 0.1342274695634842
      model: {}
      policy_loss: -0.20053988695144653
      total_loss: -0.20580041408538818
      vf_explained_var: 0.9432375431060791
      vf_loss: 0.9340238571166992
  load_time_ms: 1406.753
  num_steps_sampled: 8000
  num_steps_trained: 32000
  sample_time_ms: 32291.549
  update_time_ms: 3719.977
iterations_since_restore: 2
node_ip: 192.168.115.44
num_healthy_workers: 2
off_policy_estimator: {}
optimizer_steps_this_iter: 1
perf:
  cpu_util_percent: 38.31751412429379
  gpu_util_percent0: 0.0
  ram_util_percent: 18.801129943502826
  vram_util_percent0: 0.018997524752475244
pid: 23090
policy_reward_max:
  agent_policy: 145.25410290112478
  planner_policy: 171.49327194305675
policy_reward_mean:
  agent_policy: 64.50673155652849
  planner_policy: 133.02652131201128
policy_reward_min:
  agent_policy: 15.038367702716442
  planner_policy: 55.12339185110242
sampler_perf:
  mean_env_wait_ms: 2.1904080222840867
  mean_inference_ms: 2.7450845964092716
  mean_processing_ms: 0.6849787614356522
time_since_restore: 351.9558103084564
time_this_iter_s: 144.94165420532227
time_total_s: 351.9558103084564
timestamp: 1664960650
timesteps_since_restore: 8000
timesteps_this_iter: 4000
timesteps_total: 8000
training_iteration: 2

-- PPO Agents -- Steps done: 8
2022-10-05 11:06:39,144 Iter 3: steps this-iter 4000 total 12000 -> 12/5000 episodes done
2022-10-05 11:06:39,151 custom_metrics: {}
date: 2022-10-05_11-06-39
done: false
episode_len_mean: 1000.0
episode_reward_max: 525.8075341328317
episode_reward_mean: 401.09485184661304
episode_reward_min: 199.17922931462073
episodes_this_iter: 4
episodes_total: 12
experiment_id: e091da29812b42cd9a2c2920e11e4fe1
hostname: hpc-g04-node02.unitn.it
info:
  grad_time_ms: 137747.576
  learner:
    agent_policy:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 2.038001537322998
      entropy_coeff: 0.02500000037252903
      kl: 0.14839474856853485
      model: {}
      policy_loss: -0.21102286875247955
      total_loss: -0.22354330122470856
      vf_explained_var: 0.9601010084152222
      vf_loss: 0.7685918807983398
  load_time_ms: 1297.84
  num_steps_sampled: 12000
  num_steps_trained: 48000
  sample_time_ms: 25063.951
  update_time_ms: 2484.963
iterations_since_restore: 3
node_ip: 192.168.115.44
num_healthy_workers: 2
off_policy_estimator: {}
optimizer_steps_this_iter: 1
perf:
  cpu_util_percent: 41.5585635359116
  gpu_util_percent0: 0.0
  ram_util_percent: 19.26408839779005
  vram_util_percent0: 0.018997524752475244
pid: 23090
policy_reward_max:
  agent_policy: 145.25410290112478
  planner_policy: 195.90378625203343
policy_reward_mean:
  agent_policy: 64.62066510699299
  planner_policy: 142.61219141864046
policy_reward_min:
  agent_policy: 12.657368920383849
  planner_policy: 55.12339185110242
sampler_perf:
  mean_env_wait_ms: 2.138131487473997
  mean_inference_ms: 2.6801649172571014
  mean_processing_ms: 0.6768712853664044
time_since_restore: 500.31092381477356
time_this_iter_s: 148.35511350631714
time_total_s: 500.31092381477356
timestamp: 1664960799
timesteps_since_restore: 12000
timesteps_this_iter: 4000
timesteps_total: 12000
training_iteration: 3

-- PPO Agents -- Steps done: 12
=>> PBS: job killed: walltime 688 exceeded limit 600
*** Aborted at 1664960838 (unix time) try "date -d @1664960838" if you are using GNU date ***
PC: @                0x0 (unknown)
*** SIGTERM (@0xfe7c) received by PID 23090 (TID 0x2ac0fffe93c0) from PID 65148; stack trace: ***
    @     0x2ac1001e2630 (unknown)
    @     0x2ac100bf0bf9 syscall
    @     0x2ac148c3a479 nsync::nsync_mu_semaphore_p_with_deadline()
2022-10-05 11:07:18,819	ERROR worker.py:1092 -- listen_error_messages_raylet: Connection closed by server.
2022-10-05 11:07:18,824	ERROR import_thread.py:93 -- ImportThread: Connection closed by server.
    @     0x2ac148c39ab9 nsync::nsync_sem_wait_with_cancel_()
    @     0x2ac148c370e3 nsync::nsync_cv_wait_with_deadline_generic()
    @     0x2ac148c375e3 nsync::nsync_cv_wait_with_deadline()
    @     0x2ac147cb140b tensorflow::DirectSession::RunInternal()
    @     0x2ac147cb2829 tensorflow::DirectSession::Run()
    @     0x2ac147c9b134 tensorflow::DirectSession::Run()
    @     0x2ac137fb68c2 tensorflow::SessionRef::Run()
    @     0x2ac138411f5e TF_Run_Helper()
    @     0x2ac138412c28 TF_SessionRun
    @     0x2ac137fb001f tensorflow::TF_SessionRun_wrapper_helper()
    @     0x2ac137fb00c2 tensorflow::TF_SessionRun_wrapper()
    @     0x2ac16bb2c274 _ZZN8pybind1112cpp_function10initializeIZL32pybind11_init__pywrap_tf_sessionRNS_7module_EEUlP10TF_SessionP9TF_BufferRKNS_6handleERKSt6vectorI9TF_OutputSaISC_EERKSB_IP12TF_OperationSaISI_EES7_E15_NS_6objectEJS5_S7_SA_SG_SM_S7_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES15_
    @     0x2ac16bb15c98 pybind11::cpp_function::dispatcher()
    @           0x46299c _PyCFunction_FastCallKeywords
    @           0x4fc23a _PyEval_EvalFrameDefault
    @           0x46217a function_code_fastcall
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x501a88 _PyEval_EvalCodeWithName
    @           0x468f5f PyObject_Call
    @           0x4f91a4 _PyEval_EvalFrameDefault
    @           0x501a88 _PyEval_EvalCodeWithName
    @           0x4625aa _PyFunction_FastCallKeywords
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x501ed8 _PyEval_EvalCodeWithName
    @           0x4625aa _PyFunction_FastCallKeywords
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x46217a function_code_fastcall
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x501a88 _PyEval_EvalCodeWithName
