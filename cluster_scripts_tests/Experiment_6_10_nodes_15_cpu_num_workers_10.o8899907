Allocate Nodes = <hpc-c11-node12 hpc-c11-node08 hpc-c11-node16 hpc-c11-node11 hpc-c11-node13 hpc-c04-node07 hpc-g04-node01 hpc-c03-node24 hpc-c03-node20 hpc-c03-node12>
set up ray cluster...


Working with node hpc-c11-node12
first allocate node - use as headnode ...
2022-10-05 10:23:36,059	INFO scripts.py:357 -- Using IP address 192.168.115.66 for this node.
2022-10-05 10:23:36,087	INFO resource_spec.py:212 -- Starting Ray with 653.47 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:23:39,186	INFO services.py:1170 -- View the Ray dashboard at [1m[32mlocalhost:8265[39m[22m
2022-10-05 10:23:39,330	INFO scripts.py:387 -- 
Started Ray on this node. You can add additional nodes to the cluster by calling

    ray start --address='192.168.115.66:3679' --redis-password='1e1f5c07-3eb0-4ff3-9c82-92024467fe6c'

from the node you wish to add. You can connect a driver to the cluster from Python by running

    import ray
    ray.init(address='auto', redis_password='1e1f5c07-3eb0-4ff3-9c82-92024467fe6c')

If you have trouble connecting from a different machine, check that your firewall is configured properly. If you wish to terminate the processes that have been started, run

    ray stop

Working with node hpc-c11-node08
then allocate other nodes:  1
node NAME: hpc-c11-node08.unitn.it
node IP: 192.168.115.142
dest IP: 192.168.115.66:3679
2022-10-05 10:23:46,838	INFO scripts.py:429 -- Using IP address 192.168.115.142 for this node.
2022-10-05 10:23:46,848	INFO resource_spec.py:212 -- Starting Ray with 312.26 GiB memory available for workers and up to 133.84 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:23:46,874	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c11-node08.unitn.it

Working with node hpc-c11-node16
then allocate other nodes:  2
node NAME: hpc-c11-node16.unitn.it
node IP: 192.168.115.95
dest IP: 192.168.115.66:3679
2022-10-05 10:23:57,880	INFO scripts.py:429 -- Using IP address 192.168.115.95 for this node.
2022-10-05 10:23:57,887	INFO resource_spec.py:212 -- Starting Ray with 799.27 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:23:57,918	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c11-node16.unitn.it

Working with node hpc-c11-node11
then allocate other nodes:  3
node NAME: hpc-c11-node11.unitn.it
node IP: 192.168.115.78
dest IP: 192.168.115.66:3679
2022-10-05 10:24:08,084	INFO scripts.py:429 -- Using IP address 192.168.115.78 for this node.
2022-10-05 10:24:08,093	INFO resource_spec.py:212 -- Starting Ray with 711.38 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:24:08,139	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c11-node11.unitn.it

Working with node hpc-c11-node13
then allocate other nodes:  4
node NAME: hpc-c11-node13.unitn.it
node IP: 192.168.115.83
dest IP: 192.168.115.66:3679
2022-10-05 10:24:17,566	INFO scripts.py:429 -- Using IP address 192.168.115.83 for this node.
2022-10-05 10:24:17,577	INFO resource_spec.py:212 -- Starting Ray with 782.57 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:24:17,608	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c11-node13.unitn.it

Working with node hpc-c04-node07
then allocate other nodes:  5
node NAME: hpc-c04-node07.unitn.it
node IP: 192.168.115.118
dest IP: 192.168.115.66:3679
2022-10-05 10:24:27,431	INFO scripts.py:429 -- Using IP address 192.168.115.118 for this node.
2022-10-05 10:24:27,434	INFO resource_spec.py:212 -- Starting Ray with 253.61 GiB memory available for workers and up to 108.71 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:24:27,468	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c04-node07.unitn.it

Working with node hpc-g04-node01
then allocate other nodes:  6
node NAME: hpc-g04-node01.unitn.it
node IP: 192.168.115.24
dest IP: 192.168.115.66:3679
2022-10-05 10:24:36,417	INFO scripts.py:429 -- Using IP address 192.168.115.24 for this node.
2022-10-05 10:24:36,420	INFO resource_spec.py:212 -- Starting Ray with 529.44 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:24:36,439	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-g04-node01.unitn.it

Working with node hpc-c03-node24
then allocate other nodes:  7
node NAME: hpc-c03-node24.unitn.it
node IP: 192.168.115.12
dest IP: 192.168.115.66:3679
2022-10-05 10:24:46,744	INFO scripts.py:429 -- Using IP address 192.168.115.12 for this node.
2022-10-05 10:24:46,747	INFO resource_spec.py:212 -- Starting Ray with 234.72 GiB memory available for workers and up to 100.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:24:46,774	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c03-node24.unitn.it

Working with node hpc-c03-node20
then allocate other nodes:  8
node NAME: hpc-c03-node20.unitn.it
node IP: 192.168.115.56
dest IP: 192.168.115.66:3679
2022-10-05 10:24:57,225	INFO scripts.py:429 -- Using IP address 192.168.115.56 for this node.
2022-10-05 10:24:57,228	INFO resource_spec.py:212 -- Starting Ray with 210.6 GiB memory available for workers and up to 90.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:24:57,267	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c03-node20.unitn.it

Working with node hpc-c03-node12
then allocate other nodes:  9
node NAME: hpc-c03-node12.unitn.it
node IP: 192.168.115.105
dest IP: 192.168.115.66:3679
2022-10-05 10:25:06,820	INFO scripts.py:429 -- Using IP address 192.168.115.105 for this node.
2022-10-05 10:25:06,824	INFO resource_spec.py:212 -- Starting Ray with 210.55 GiB memory available for workers and up to 90.25 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).
2022-10-05 10:25:06,855	INFO scripts.py:438 -- 
Started Ray on this node. If you wish to terminate the processes that have been started, run

    ray stop
exiting hpc-c03-node12.unitn.it

done, now launching python program
Inside covid19_components.py: 0 GPUs are available.
No GPUs found! Running the simulation on a CPU.
Inside covid19_env.py: 0 GPUs are available.
No GPUs found! Running the simulation on a CPU.
2022-10-05 10:26:35,877	WARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster's _internal_config.
2022-10-05 10:26:35,904 seed (final): 16315000
2022-10-05 10:26:35,975	INFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution
2022-10-05 10:26:36,596	INFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
2022-10-05 10:26:50,047	WARNING worker.py:1090 -- The actor or task with ID ffffffffffffffff45b95b1c0100 is pending and cannot currently be scheduled. It requires {CPU: 1.000000} for execution and {CPU: 1.000000} for placement, but this node only has remaining {node:192.168.115.66: 1.000000}, {CPU: 96.000000}, {memory: 653.466797 GiB}, {object_store_memory: 128.515625 GiB}. In total there are 0 pending tasks and 2 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
2022-10-05 10:27:00,152	INFO trainable.py:180 -- _setup took 23.558 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2022-10-05 10:27:00,153	INFO trainable.py:217 -- Getting current IP.
2022-10-05 10:27:15,562	INFO trainable.py:180 -- _setup took 15.335 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2022-10-05 10:27:15,563	INFO trainable.py:217 -- Getting current IP.
2022-10-05 10:27:15,567 Not restoring trainer...
2022-10-05 10:27:15,567 Starting with fresh agent TF weights.
2022-10-05 10:27:15,567 Starting with fresh planner TF weights.
Training
-- PPO Agents -- Steps done: 0
2022-10-05 10:31:03,574 Iter 1: steps this-iter 4000 total 4000 -> 4/5000 episodes done
2022-10-05 10:31:03,580 custom_metrics: {}
date: 2022-10-05_10-31-03
done: false
episode_len_mean: 1000.0
episode_reward_max: 153.63661444539417
episode_reward_mean: 127.9257279874712
episode_reward_min: 68.4501638009471
episodes_this_iter: 4
episodes_total: 4
experiment_id: 0bfab3aadd544ae5bc964367d10e1beb
hostname: hpc-c11-node12.unitn.it
info:
  grad_time_ms: 168497.965
  learner:
    agent_policy:
      cur_kl_coeff: 0.0
      cur_lr: 0.0003000000142492354
      entropy: 1.888685703277588
      entropy_coeff: 0.02500000037252903
      kl: 0.10545098036527634
      model: {}
      policy_loss: -0.15590550005435944
      total_loss: -0.15472395718097687
      vf_explained_var: 0.8592199087142944
      vf_loss: 0.9679731130599976
  load_time_ms: 1690.318
  num_steps_sampled: 4000
  num_steps_trained: 16000
  sample_time_ms: 48476.154
  update_time_ms: 8037.139
iterations_since_restore: 1
node_ip: 192.168.115.66
num_healthy_workers: 2
off_policy_estimator: {}
optimizer_steps_this_iter: 1
perf:
  cpu_util_percent: 78.78729641693812
  ram_util_percent: 15.460912052117264
pid: 52677
policy_reward_max:
  agent_policy: 63.684188038426846
  planner_policy: 43.92067806991752
policy_reward_mean:
  agent_policy: 23.827472627936096
  planner_policy: 32.61583747572719
policy_reward_min:
  agent_policy: -0.8471739336894606
  planner_policy: 17.102203543015587
sampler_perf:
  mean_env_wait_ms: 2.233326822325684
  mean_inference_ms: 3.28378198386311
  mean_processing_ms: 0.7096305601242958
time_since_restore: 227.02054357528687
time_this_iter_s: 227.02054357528687
time_total_s: 227.02054357528687
timestamp: 1664958663
timesteps_since_restore: 4000
timesteps_this_iter: 4000
timesteps_total: 4000
training_iteration: 1

2022-10-05 10:31:03,797 >> Wrote dense logs to: /home/ettore.saggiorato/ai-economist-ppo-decision-tree/ai-economist/tutorials/rllib/experiments/check/phase1_gpu/dense_logs/logs_0000000000004000
-- PPO Agents -- Steps done: 4
=>> PBS: job killed: walltime 601 exceeded limit 600
*** Aborted at 1664958805 (unix time) try "date -d @1664958805" if you are using GNU date ***
PC: @                0x0 (unknown)
2022-10-05 10:33:25,512	ERROR import_thread.py:93 -- ImportThread: Connection closed by server.
2022-10-05 10:33:25,511	ERROR worker.py:1092 -- listen_error_messages_raylet: Connection closed by server.
*** SIGTERM (@0xd6a) received by PID 52677 (TID 0x2b1b9d3413c0) from PID 3434; stack trace: ***
    @     0x2b1b9d53f630 (unknown)
    @     0x2b1b9df4de29 syscall
    @     0x2b1be5f93479 nsync::nsync_mu_semaphore_p_with_deadline()
    @     0x2b1be5f92ab9 nsync::nsync_sem_wait_with_cancel_()
    @     0x2b1be5f900e3 nsync::nsync_cv_wait_with_deadline_generic()
    @     0x2b1be5f905e3 nsync::nsync_cv_wait_with_deadline()
    @     0x2b1be500a40b tensorflow::DirectSession::RunInternal()
    @     0x2b1be500b829 tensorflow::DirectSession::Run()
    @     0x2b1be4ff4134 tensorflow::DirectSession::Run()
    @     0x2b1bd530f8c2 tensorflow::SessionRef::Run()
    @     0x2b1bd576af5e TF_Run_Helper()
    @     0x2b1bd576bc28 TF_SessionRun
    @     0x2b1bd530901f tensorflow::TF_SessionRun_wrapper_helper()
    @     0x2b1bd53090c2 tensorflow::TF_SessionRun_wrapper()
    @     0x2b1c08bec274 _ZZN8pybind1112cpp_function10initializeIZL32pybind11_init__pywrap_tf_sessionRNS_7module_EEUlP10TF_SessionP9TF_BufferRKNS_6handleERKSt6vectorI9TF_OutputSaISC_EERKSB_IP12TF_OperationSaISI_EES7_E15_NS_6objectEJS5_S7_SA_SG_SM_S7_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES15_
    @     0x2b1c08bd5c98 pybind11::cpp_function::dispatcher()
    @           0x46299c _PyCFunction_FastCallKeywords
    @           0x4fc23a _PyEval_EvalFrameDefault
    @           0x46217a function_code_fastcall
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x501a88 _PyEval_EvalCodeWithName
    @           0x468f5f PyObject_Call
    @           0x4f91a4 _PyEval_EvalFrameDefault
    @           0x501a88 _PyEval_EvalCodeWithName
    @           0x4625aa _PyFunction_FastCallKeywords
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x501ed8 _PyEval_EvalCodeWithName
    @           0x4625aa _PyFunction_FastCallKeywords
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x46217a function_code_fastcall
    @           0x4f79ff _PyEval_EvalFrameDefault
    @           0x501a88 _PyEval_EvalCodeWithName
